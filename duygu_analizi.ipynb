{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61fbc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri Seti Başarıyla Yüklendi!\n",
      "\n",
      "İlk 5 satır:\n",
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "\n",
      "Veri Seti Bilgileri:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "\n",
      "Duygu Dağılımı:\n",
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Metin Sütunu İçin Bazı İstatistikler (Karakter Sayısı):\n",
      "count    50000.000000\n",
      "mean      1309.431020\n",
      "std        989.728014\n",
      "min         32.000000\n",
      "25%        699.000000\n",
      "50%        970.000000\n",
      "75%       1590.250000\n",
      "max      13704.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Veri setinin dosya yolu. Eğer dosya aynı klasördeyse sadece adı yeterli.\n",
    "# Eğer farklı bir yerde ise, tam dosya yolunu belirtmelisin.\n",
    "file_path = 'IMDB Dataset.csv'\n",
    "\n",
    "try:\n",
    "    # CSV dosyasını oku\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(\"Veri Seti Başarıyla Yüklendi!\")\n",
    "    print(\"\\nİlk 5 satır:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nVeri Seti Bilgileri:\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\nDuygu Dağılımı:\")\n",
    "    print(df['sentiment'].value_counts())\n",
    "\n",
    "    print(\"\\nMetin Sütunu İçin Bazı İstatistikler (Karakter Sayısı):\")\n",
    "    df['text_length'] = df['review'].apply(len)\n",
    "    print(df['text_length'].describe())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Hata: '{file_path}' dosyası bulunamadı. Lütfen dosya yolunu kontrol edin veya dosyanın aynı klasörde olduğundan emin olun.\")\n",
    "except Exception as e:\n",
    "    print(f\"Bir hata oluştu: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f013e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal ve Temizlenmiş Yorumların İlk 5 Satırı:\n",
      "                                              review  \\\n",
      "0  One of the other reviewers has mentioned that ...   \n",
      "1  A wonderful little production. <br /><br />The...   \n",
      "2  I thought this was a wonderful way to spend ti...   \n",
      "3  Basically there's a family where a little boy ...   \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
      "\n",
      "                                      review_cleaned  \n",
      "0  One of the other reviewers has mentioned that ...  \n",
      "1  A wonderful little production. The filming tec...  \n",
      "2  I thought this was a wonderful way to spend ti...  \n",
      "3  Basically there's a family where a little boy ...  \n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  \n",
      "\n",
      "-----------------------------------------------------\n",
      "Rastgele Bir Yorumun Orijinal ve Temizlenmiş Hali (Örnek Indeks 2):\n",
      "Orijinal: I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n",
      "Temizlenmiş: I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Metindeki HTML etiketlerini kaldırır.\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "# 'review' sütununa HTML etiketlerini temizleme fonksiyonunu uygula\n",
    "df['review_cleaned'] = df['review'].apply(remove_html_tags)\n",
    "\n",
    "# Temizlenmiş ilk 5 yorumu ve orijinal yorumları karşılaştır\n",
    "print(\"Orijinal ve Temizlenmiş Yorumların İlk 5 Satırı:\")\n",
    "print(df[['review', 'review_cleaned']].head())\n",
    "\n",
    "# Değişikliğin olup olmadığını görmek için rastgele bir yorumu kontrol edebiliriz\n",
    "# Örneğin, 3. yorumu alalım (indeksi 2)\n",
    "print(\"\\n-----------------------------------------------------\")\n",
    "print(\"Rastgele Bir Yorumun Orijinal ve Temizlenmiş Hali (Örnek Indeks 2):\")\n",
    "print(f\"Orijinal: {df['review'].iloc[2]}\")\n",
    "print(f\"Temizlenmiş: {df['review_cleaned'].iloc[2]}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008a4067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Küçük Harf ve Noktalama Temizliği Sonrası İlk 5 Yorum:\n",
      "                                      review_cleaned\n",
      "0  one of the other reviewers has mentioned that ...\n",
      "1  a wonderful little production the filming tech...\n",
      "2  i thought this was a wonderful way to spend ti...\n",
      "3  basically theres a family where a little boy j...\n",
      "4  petter matteis love in the time of money is a ...\n",
      "\n",
      "-----------------------------------------------------\n",
      "Rastgele Bir Yorumun Noktalama Temizliği Sonrası Hali (Örnek Indeks 2):\n",
      "Temizlenmiş (Yeni Hali): i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovethis was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanthis may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re # Eğer regex kullanacaksan\n",
    "\n",
    "# Küçük harfe çevirme\n",
    "df['review_cleaned'] = df['review_cleaned'].str.lower()\n",
    "\n",
    "# Noktalama işaretlerini kaldırma (bir yöntem)\n",
    "# df['review_cleaned'] = df['review_cleaned'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "# Noktalama işaretlerini kaldırma (başka bir yöntem, regex ile)\n",
    "df['review_cleaned'] = df['review_cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "\n",
    "# Temizlenmiş (küçük harfe çevrilmiş ve noktalama işaretleri kaldırılmış) ilk 5 yorumu kontrol et\n",
    "print(\"Küçük Harf ve Noktalama Temizliği Sonrası İlk 5 Yorum:\")\n",
    "print(df[['review_cleaned']].head())\n",
    "\n",
    "# Rastgele bir örnek yorumu tekrar kontrol edebilirsin\n",
    "print(\"\\n-----------------------------------------------------\")\n",
    "print(\"Rastgele Bir Yorumun Noktalama Temizliği Sonrası Hali (Örnek Indeks 2):\")\n",
    "print(f\"Temizlenmiş (Yeni Hali): {df['review_cleaned'].iloc[2]}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19981e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durak Kelimeler Temizliği Sonrası İlk 5 Yorum:\n",
      "                                      review_cleaned\n",
      "0  one reviewers mentioned watching 1 oz episode ...\n",
      "1  wonderful little production filming technique ...\n",
      "2  thought wonderful way spend time hot summer we...\n",
      "3  basically theres family little boy jake thinks...\n",
      "4  petter matteis love time money visually stunni...\n",
      "\n",
      "-----------------------------------------------------\n",
      "Rastgele Bir Yorumun Durak Kelimeler Temizliği Sonrası Hali (Örnek Indeks 2):\n",
      "Temizlenmiş (Yeni Hali): thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown lovethis id laughed one woodys comedies years dare say decade ive never impressed scarlet johanson managed tone sexy image jumped right average spirited young womanthis may crown jewel career wittier devil wears prada interesting superman great comedy go see friends\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# İngilizce durak kelimeleri yükle\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Metindeki durak kelimeleri kaldırır.\"\"\"\n",
    "    words = text.split() # Metni kelimelere ayır (tokenization)\n",
    "    # Her kelimeyi kontrol et ve eğer durak kelime listesinde değilse, o kelimeyi koru\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words) # Kalan kelimeleri tekrar birleştir\n",
    "\n",
    "# 'review_cleaned' sütununa durak kelime temizleme fonksiyonunu uygula\n",
    "df['review_cleaned'] = df['review_cleaned'].apply(remove_stopwords)\n",
    "\n",
    "# Temizlenmiş ilk 5 yorumu kontrol et\n",
    "print(\"Durak Kelimeler Temizliği Sonrası İlk 5 Yorum:\")\n",
    "print(df[['review_cleaned']].head())\n",
    "\n",
    "# Rastgele bir örnek yorumu tekrar kontrol et\n",
    "print(\"\\n-----------------------------------------------------\")\n",
    "print(\"Rastgele Bir Yorumun Durak Kelimeler Temizliği Sonrası Hali (Örnek Indeks 2):\")\n",
    "print(f\"Temizlenmiş (Yeni Hali): {df['review_cleaned'].iloc[2]}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaa884f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adım 4: Metin Temsili (TF-IDF Vectorization) ---\n",
      "TF-IDF Matrisinin Boyutları (Yorum Sayısı, Benzersiz Kelime Sayısı): (50000, 10000)\n",
      "\n",
      "Metin temsil adımı tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"\\n--- Adım 4: Metin Temsili (TF-IDF Vectorization) ---\")\n",
    "\n",
    "# TF-IDF Vectorizer nesnesini oluştur\n",
    "# max_features: En sık geçen 10.000 kelimeyi al (önemli kelimeleri sınırlamak için)\n",
    "# min_df: Bir kelime en az 5 belgede geçmiyorsa göz ardı et (çok nadir kelimeleri elemek için)\n",
    "# max_df: Bir kelime belgelerin %70'inden fazlasında geçiyorsa göz ardı et (çok yaygın kelimeleri elemek için)\n",
    "vectorizer = TfidfVectorizer(max_features=10000, min_df=5, max_df=0.7)\n",
    "\n",
    "# Temizlenmiş yorumları (df['review_cleaned']) TF-IDF vektörlerine dönüştür\n",
    "# X artık modelin kullanacağı sayısal özellik matrisi olacak\n",
    "X = vectorizer.fit_transform(df['review_cleaned'])\n",
    "\n",
    "# Oluşan TF-IDF matrisinin boyutlarını kontrol et\n",
    "# Çıktı (yorum sayısı, benzersiz ve filtrelenmiş kelime sayısı) şeklinde olacaktır.\n",
    "print(\"TF-IDF Matrisinin Boyutları (Yorum Sayısı, Benzersiz Kelime Sayısı):\", X.shape)\n",
    "\n",
    "# İsteğe bağlı: Oluşturulan kelime dağarcığının (vocabulary) ilk birkaç elemanını görmek\n",
    "# Eğer istersen bu satırı yorumdan çıkarıp kelimeleri görebilirsin.\n",
    "# print(\"\\nVectorizer Kelime Dağarcığından İlk 10 Kelime:\")\n",
    "# print(vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "print(\"\\nMetin temsil adımı tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9459c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train boyutu: (40000, 10000)\n",
      "X_test boyutu: (10000, 10000)\n",
      "y_train boyutu: (40000,)\n",
      "y_test boyutu: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Sentiment etiketlerini sayısal formata çevir ('positive' -> 1, 'negative' -> 0)\n",
    "# 'sentiment_numeric' adında yeni bir sütun oluşturuyoruz\n",
    "df['sentiment_numeric'] = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "# 2. Özellikler (X) ve Hedef Değişken (y) tanımla\n",
    "# X zaten TF-IDF matrisimiz (bir önceki adımda oluşturuldu).\n",
    "# y ise yeni oluşturduğumuz sayısal sentiment sütunu.\n",
    "y = df['sentiment_numeric']\n",
    "\n",
    "# 3. Veri setini %80 eğitim, %20 test olarak ayır\n",
    "# random_state değerini sabit tutarak her çalıştığında aynı bölmeyi elde edebiliriz.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Bölümlenmiş setlerin boyutlarını kontrol et\n",
    "print(f\"X_train boyutu: {X_train.shape}\")\n",
    "print(f\"X_test boyutu: {X_test.shape}\")\n",
    "print(f\"y_train boyutu: {y_train.shape}\")\n",
    "print(f\"y_test boyutu: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fca3abd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adım 5: Modeli Seçme ve Eğitme (Logistic Regression) ---\n",
      "Model eğitiliyor...\n",
      "Model eğitimi tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "print(\"\\n--- Adım 5: Modeli Seçme ve Eğitme (Logistic Regression) ---\")\n",
    "\n",
    "# Lojistik Regresyon modelini oluştur\n",
    "# random_state: Sonuçların tekrarlanabilirliği için\n",
    "# solver='liblinear': Küçük veri setleri için genellikle iyi çalışan bir algoritma\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# Modeli eğitim verileri üzerinde eğit\n",
    "# Bu adım biraz zaman alabilir (40.000 yorum için)\n",
    "print(\"Model eğitiliyor...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model eğitimi tamamlandı.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
